{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZjRn0WCI_6S"
      },
      "outputs": [],
      "source": [
        "%pip install tavily-python\n",
        "%pip install beautifulsoup4\n",
        "%pip install requests\n",
        "%pip install chromadb==0.4.14\n",
        "%pip install langchain_community langchain_openai langchain_chroma langgraph\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoVpWKO_I_6T"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "class Task(BaseModel):\n",
        "    agent: Literal[\n",
        "        \"content_strategist\",\n",
        "        \"communicator\",\n",
        "        \"web_search_agent\",\n",
        "        \"vector_search_agent\",\n",
        "    ] = Field(\n",
        "        ...,\n",
        "        description=\"\"\"\n",
        "        작업을 수행하는 agent의 종류.\n",
        "        - content_strategist: 콘텐츠 전략을 수립하는 작업을 수행한다. 사용자의 요구사항이 명확해졌을 때 사용한다. AI 팀의 콘텐츠 전략을 결정하고, 전체 책의 목차(outline)를 작성한다.\n",
        "        - communicator: AI 팀에서 해야 할 일을 스스로 판단할 수 없을 때 사용한다. 사용자에게 진행상황을 사용자에게 보고하고, 다음 지시를 물어본다.\n",
        "        - web_search_agent: 웹 검색을 통해 목차(outline) 작성에 필요한 정보를 확보한다.\n",
        "        - vector_search_agent: 벡터 DB 검색을 통해 목차(outline) 작성에 필요한 정보를 확보한다.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    done: bool = Field(..., description=\"종료 여부\")\n",
        "    description: str = Field(..., description=\"어떤 작업을 해야 하는지에 대한 설명\")\n",
        "\n",
        "    done_at: str = Field(..., description=\"할 일이 완료된 날짜와 시간\")\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"agent\": self.agent,\n",
        "            \"done\": self.done,\n",
        "            \"description\": self.description,\n",
        "            \"done_at\": self.done_at\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "wB6kwOiTMDx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "mvd04TpzMSS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tavily import TavilyClient\n",
        "from langchain_core.tools import tool\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from datetime import datetime\n",
        "import json\n",
        "import os\n",
        "# absolute_path = os.path.abspath(__file__) # 현재 파일의 절대 경로 반환\n",
        "current_path = \".\" #os.path.dirname(absolute_path) # 현재 .py 파일이 있는 폴더 경로\n",
        "\n",
        "# RAG를 위한 설정\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "import chromadb\n",
        "\n",
        "# 오픈AI Embedding 설정\n",
        "embedding = OpenAIEmbeddings(model='text-embedding-3-large', api_key=OPENAI_API_KEY)\n",
        "\n",
        "# 크로마 DB 저장 경로 설정\n",
        "persist_directory = f\"./data/chroma_store\"\n",
        "client = chromadb.PersistentClient(path=persist_directory)\n",
        "\n",
        "# Chroma 객체 생성\n",
        "vectorstore = Chroma(\n",
        "    client=client,\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function=embedding\n",
        ")\n",
        "\n",
        "@tool\n",
        "def web_search(query: str):\n",
        "    \"\"\"\n",
        "    주어진 query에 대해 웹검색을 하고, 결과를 반환한다.\n",
        "\n",
        "    Args:\n",
        "        query (str): 검색어\n",
        "\n",
        "    Returns:\n",
        "        dict: 검색 결과\n",
        "    \"\"\"\n",
        "    client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "\n",
        "    content = client.search(\n",
        "        query,\n",
        "        search_depth=\"advanced\",\n",
        "        include_raw_content=True,\n",
        "    )\n",
        "\n",
        "    results = content[\"results\"]   #②\n",
        "\n",
        "    for result in results:\n",
        "        if result[\"raw_content\"] is None:\n",
        "            try:\n",
        "                result[\"raw_content\"] = load_web_page(result[\"url\"])\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading page: {result['url']}\")\n",
        "                print(e)\n",
        "                result[\"raw_content\"] = result[\"content\"]\n",
        "\n",
        "    resources_json_path = f'{current_path}/data/resources_{datetime.now().strftime(\"%Y_%m%d_%H%M%S\")}.json'\n",
        "    with open(resources_json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    return results, resources_json_path  # 검색 결과와 JSON 파일 경로 반환\n",
        "\n",
        "\n",
        "def web_page_to_document(web_page):\n",
        "    # raw_content와 content 중 정보가 많은 것을 page_content로 한다.\n",
        "    if len(web_page['raw_content']) > len(web_page['content']):\n",
        "        page_content = web_page['raw_content']\n",
        "    else:\n",
        "        page_content = web_page['content']\n",
        "    # 랭체인 Document로 변환\n",
        "    document = Document(\n",
        "        page_content=page_content,\n",
        "        metadata={\n",
        "            'title': web_page['title'],\n",
        "            'source': web_page['url']\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return document\n",
        "\n",
        "\n",
        "def web_page_json_to_documents(json_file):\n",
        "    with open(json_file, \"r\", encoding='utf-8') as f:\n",
        "        resources = json.load(f)\n",
        "\n",
        "    documents = []\n",
        "\n",
        "    for web_page in resources:\n",
        "        document = web_page_to_document(web_page)\n",
        "        documents.append(document)\n",
        "\n",
        "    return documents\n",
        "\n",
        "\n",
        "def split_documents(documents, chunk_size=1000, chunk_overlap=100):\n",
        "    print('Splitting documents...')\n",
        "    print(f\"{len(documents)}개의 문서를 {chunk_size}자 크기로 중첩 {chunk_overlap}자로 분할합니다.\\n\")\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
        "    )\n",
        "\n",
        "    splits = text_splitter.split_documents(documents)\n",
        "\n",
        "    print(f\"총 {len(splits)}개의 문서로 분할되었습니다.\")\n",
        "    return splits\n",
        "\n",
        "# documents를 chroma DB에 저장하는 함수\n",
        "def documents_to_chroma(documents, chunk_size=1000, chunk_overlap=100):\n",
        "    print(\"Documents를 Chroma DB에 저장합니다.\")\n",
        "\n",
        "    # documents의 url 가져오기\n",
        "    urls = [document.metadata['source'] for document in documents]\n",
        "\n",
        "    # 이미 vectorstore에 저장된 urls 가져오기\n",
        "    stored_metadatas = vectorstore._collection.get()['metadatas']\n",
        "    stored_web_urls = [metadata['source'] for metadata in stored_metadatas]\n",
        "\n",
        "    # 새로운 urls만 남기기\n",
        "    new_urls = set(urls) - set(stored_web_urls)\n",
        "\n",
        "    # 새로운 urls에 대한 documents만 남기기\n",
        "    new_documents = []\n",
        "\n",
        "    for document in documents:\n",
        "        if document.metadata['source'] in new_urls:\n",
        "            new_documents.append(document)\n",
        "            print(document.metadata)\n",
        "\n",
        "    # 새로운 documents를 Chroma DB에 저장\n",
        "    splits = split_documents(new_documents, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "\n",
        "    # 크로마 DB에 저장\n",
        "    if splits:\n",
        "        vectorstore.add_documents(splits)\n",
        "    else:\n",
        "        print(\"No new urls to process\")\n",
        "\n",
        "# json 파일에서 documents를 만들고, 그 documents들을 Chroma DB에 저장\n",
        "def add_web_pages_json_to_chroma(json_file, chunk_size=1000, chunk_overlap=100):\n",
        "    documents = web_page_json_to_documents(json_file)\n",
        "    documents_to_chroma(\n",
        "        documents,\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "\n",
        "\n",
        "def load_web_page(url: str):\n",
        "    loader = WebBaseLoader(url, verify_ssl=False)\n",
        "\n",
        "    content = loader.load()\n",
        "    raw_content = content[0].page_content.strip()   #①\n",
        "\n",
        "    while '\\n\\n\\n' in raw_content or '\\t\\t\\t' in raw_content:\n",
        "        raw_content = raw_content.replace('\\n\\n\\n', '\\n\\n')\n",
        "        raw_content = raw_content.replace('\\t\\t\\t', '\\t\\t')\n",
        "\n",
        "    return raw_content\n",
        "\n",
        "@tool\n",
        "def retrieve(query: str, top_k: int=5):\n",
        "    \"\"\"\n",
        "    주어진 query에 대해 벡터 검색을 수행하고, 결과를 반환한다.\n",
        "    \"\"\"\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": top_k})\n",
        "    retrieved_docs = retriever.invoke(query)\n",
        "\n",
        "    return retrieved_docs\n"
      ],
      "metadata": {
        "id": "67Idk0tBJdgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def save_state(current_path, state):\n",
        "    if not os.path.exists(f\"{current_path}/data\"):\n",
        "        os.makedirs(f\"{current_path}/data\")\n",
        "\n",
        "    state_dict = {}\n",
        "\n",
        "    messages = [(m.__class__.__name__, m.content) for m in state[\"messages\"]]\n",
        "    state_dict[\"messages\"] = messages\n",
        "    state_dict[\"task_history\"] = [task.to_dict() for task in state.get(\"task_history\", [])]\n",
        "\n",
        "    # references\n",
        "    references = state.get(\"references\", {\"queries\": [], \"docs\": []})\n",
        "    state_dict[\"references\"] = {\n",
        "        \"queries\": references[\"queries\"],\n",
        "        \"docs\": [doc.metadata for doc in references[\"docs\"]]\n",
        "    }\n",
        "\n",
        "    with open(f\"{current_path}/data/state.json\", \"w\", encoding='utf-8') as f:\n",
        "        json.dump(state_dict, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def get_outline(current_path):\n",
        "    outline = '아직 작성된 목차가 없습니다.'\n",
        "\n",
        "    if os.path.exists(f\"{current_path}/data/outline.md\"):\n",
        "        with open(f\"{current_path}/data/outline.md\", \"r\", encoding='utf-8') as f:\n",
        "            outline = f.read()\n",
        "    return outline\n",
        "\n",
        "def save_outline(current_path, outline):\n",
        "    if not os.path.exists(f\"{current_path}/data\"):\n",
        "        os.makedirs(f\"{current_path}/data\")\n",
        "\n",
        "    with open(f\"{current_path}/data/outline.md\", \"w\", encoding='utf-8') as f:\n",
        "        f.write(outline)\n",
        "    return outline\n"
      ],
      "metadata": {
        "id": "2fsp5NZTKRBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers.string import StrOutputParser\n",
        "from typing_extensions import TypedDict\n",
        "from typing import List\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# 현재 폴더 경로 찾기\n",
        "# 랭그래프 이미지로 저장 및 추후 작업 결과 파일 저장 경로로 활용\n",
        "# filename = os.path.basename(__file__) # 현재 파일명 반환\n",
        "# absolute_path = os.path.abspath(__file__) # 현재 파일의 절대 경로 반환\n",
        "# current_path = os.path.dirname(absolute_path) # 현재 .py 파일이 있는 폴더 경로\n",
        "\n",
        "# 모델 초기화\n",
        "llm = ChatOpenAI(model=\"gpt-4.1\", api_key=OPENAI_API_KEY)\n",
        "\n",
        "# 상태 정의\n",
        "class State(TypedDict):\n",
        "    messages: List[AnyMessage | str]\n",
        "    task_history: List[Task]\n",
        "    references: dict\n",
        "    user_request: str\n",
        "    ai_recommendation: str # AI의 추천을 저장하는 변수\n",
        "    supervisor_call_count: int # supervisor 호출 횟수를 저장하는 변수\n",
        "\n",
        "\n",
        "def business_analyst(state: State): #\n",
        "    print(\"\\n\\n============ BUSINESS ANALYST ============\")\n",
        "\n",
        "    #② (1) 시스템 프롬프트 정의\n",
        "    business_analyst_system_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        너는 책을 쓰는 AI팀의 비즈니스 애널리스트로서,\n",
        "        AI팀의 진행상황과 \"사용자 요구사항\"을 토대로,\n",
        "        현 시점에서 'ai_recommendation'과 최근 사용자의 발언을 바탕으로 요구사항이 무엇인지 판단한다.\n",
        "        지난 요청사항이 달성되었는지 판단하고, 현 시점에서 어떤 작업을 해야 하는지 결정한다.\n",
        "\n",
        "        다음과 같은 템플릿 형태로 반환한다.\n",
        "        ```\n",
        "        - 목표: OOOO \\n 방법: OOOO\n",
        "        ```\n",
        "\n",
        "        ------------------------------------\n",
        "        *AI 추천(ai_recommendation)* : {ai_recommendation}\n",
        "        ------------------------------------\n",
        "        사용자 최근 발언: {user_last_comment}\n",
        "        ------------------------------------\n",
        "        참고자료: {references}\n",
        "        ------------------------------------\n",
        "        목차 (outline): {outline}\n",
        "        ------------------------------------\n",
        "        \"messages\": {messages}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    #③ (2) 시스템 프롬프트와 모델을 연결\n",
        "    ba_chain = business_analyst_system_prompt | llm | StrOutputParser()\n",
        "\n",
        "    #(3) 상태에서 메시지를 가져옴\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # (3) 사용자의 마지막 발언을 가져옴\n",
        "    user_last_comment = None\n",
        "    for m in messages[::-1]:\n",
        "        if isinstance(m, HumanMessage):\n",
        "            user_last_comment = m.content\n",
        "            break\n",
        "\n",
        "    # (3) 입력 자료 준비\n",
        "    inputs = {\n",
        "        \"ai_recommendation\": state.get(\"ai_recommendation\", None),\n",
        "        \"previous_user_request\": state.get(\"user_request\", None),\n",
        "        \"references\": state.get(\"references\", {\"queries\": [], \"docs\": []}),\n",
        "        \"outline\": get_outline(current_path),\n",
        "        \"messages\": messages,\n",
        "        \"user_last_comment\": user_last_comment\n",
        "    }\n",
        "\n",
        "    #⑤ (4) 시스템 프롬프트를 통해 사용자 요구사항을 분석\n",
        "    user_request = ba_chain.invoke(inputs)\n",
        "\n",
        "    #⑥ (5) businessage analyst의 결과를 메시지에 추가\n",
        "    business_analyst_message = f\"[Business Analyst] {user_request}\"\n",
        "    print(business_analyst_message)\n",
        "    messages.append(AIMessage(business_analyst_message))\n",
        "\n",
        "    save_state(current_path, state) #⑦ (6) 현재 state 내용 저장\n",
        "\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"user_request\": user_request,\n",
        "        \"ai_recommendation\": \"\"\n",
        "    }\n",
        "\n",
        "\n",
        "def supervisor(state: State): # supervisor 에이전트 추가\n",
        "    print(\"\\n\\n============ SUPERVISOR ============\")\n",
        "\n",
        "    # 시스템 프롬프트 정의\n",
        "    supervisor_system_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        너는 AI 팀의 supervisor로서 AI 팀의 작업을 관리하고 지도한다.\n",
        "        사용자가 원하는 책을 써야 한다는 최종 목표를 염두에 두고,\n",
        "        사용자의 요구를 달성하기 위해 현재 해야할 일이 무엇인지 결정한다.\n",
        "\n",
        "        supervisor가 활용할 수 있는 agent는 다음과 같다.\n",
        "        - content_strategist: 사용자의 요구사항이 명확해졌을 때 사용한다. AI 팀의 콘텐츠 전략을 결정하고, 전체 책의 목차(outline)를 작성한다.\n",
        "        - communicator: AI 팀에서 해야 할 일을 스스로 판단할 수 없을 때 사용한다. 사용자에게 진행상황을 사용자에게 보고하고, 다음 지시를 물어본다.\n",
        "        - web_search_agent: vector_search_agent를 시도하고, 검색 결과(references)에 필요한 정보가 부족한 경우 사용한다. 웹 검색을 통해 해당 정보를 Vector DB에 보강한다.\n",
        "        - vector_search_agent: 목차 작성을 위해 필요한 자료를 확보하기 위해 벡터 DB 검색을 한다.\n",
        "\n",
        "        아래 내용을 고려하여, 현재 해야할 일이 무엇인지, 사용할 수 있는 agent를 단답으로 말하라.\n",
        "\n",
        "        ------------------------------------------\n",
        "        previous_outline: {outline}\n",
        "        ------------------------------------------\n",
        "        messages:\n",
        "        {messages}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # 체인 연결\n",
        "    supervisor_chain = supervisor_system_prompt | llm. with_structured_output(Task)\n",
        "\n",
        "    # 메시지 가져오기\n",
        "    messages = state.get(\"messages\", [])\t\t#⑤\n",
        "\n",
        "    # inputs 설정\n",
        "    inputs = {\n",
        "        \"messages\": messages,\n",
        "        \"outline\": get_outline(current_path)\n",
        "    }\n",
        "\n",
        "    supervisor_call_count = state.get(\"supervisor_call_count\", 0)\n",
        "\n",
        "    if supervisor_call_count > 2:\n",
        "        print(\"Supervisor 호출 횟수 초과: Communicator 호출\")\n",
        "        task = Task(\n",
        "            agent=\"communicator\",\n",
        "            done=False,\n",
        "            description=\"supervisor 호출 횟수 초과했으므로, 현재까지의 진행상황을 사용자에게 보고한다. \",\n",
        "            done_at=\"\",\n",
        "        )\n",
        "    else:\n",
        "        task = supervisor_chain.invoke(inputs)\n",
        "\n",
        "    task_history = state.get(\"task_history\", [])    # 작업 이력 가져오기\n",
        "    task_history.append(task)                    \t# 작업 이력에 추가\n",
        "\n",
        "    # 메시지 추가\n",
        "    supervisor_message = AIMessage(f\"[Supervisor] {task}\")\n",
        "    messages.append(supervisor_message)\n",
        "    print(supervisor_message.content)\n",
        "\n",
        "    # state 업데이트\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"task_history\": task_history,\n",
        "        \"supervisor_call_count\": supervisor_call_count + 1\n",
        "    }\n",
        "\n",
        "# supervisor's route\n",
        "def supervisor_router(state: State):\n",
        "    task = state['task_history'][-1]\n",
        "    return task.agent\n",
        "\n",
        "def vector_search_agent(state: State):\n",
        "    print(\"\\n\\n============ VECTOR SEARCH AGENT ============\")\n",
        "\n",
        "    tasks = state.get(\"task_history\", [])\n",
        "    task = tasks[-1]\n",
        "    if task.agent != \"vector_search_agent\":\n",
        "        raise ValueError(f\"Vector Search Agent가 아닌 agent가 Vector Search Agent를 시도하고 있습니다.\\n {task}\")\n",
        "\n",
        "    vector_search_system_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        너는 다른 AI Agent 들이 수행한 작업을 바탕으로,\n",
        "        목차(outline) 작성에 필요한 정보를 벡터 검색을 통해 찾아내는 Agent이다.\n",
        "\n",
        "        현재 목차(outline)을 작성하는데 필요한 정보를 확보하기 위해,\n",
        "        다음 내용을 활용해 적절한 벡터 검색을 수행하라.\n",
        "\n",
        "        - 검색 목적: {mission}\n",
        "        --------------------------------\n",
        "        - 과거 검색 내용: {references}\n",
        "        --------------------------------\n",
        "        - 이전 대화 내용: {messages}\n",
        "        --------------------------------\n",
        "        - 목차(outline): {outline}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # inputs 설정\n",
        "    mission = task.description\n",
        "    references = state.get(\"references\", {\"queries\": [], \"docs\": []})\n",
        "    messages = state[\"messages\"]\n",
        "    outline = get_outline(current_path)\n",
        "\n",
        "    inputs = {\n",
        "        \"mission\": mission,\n",
        "        \"references\": references,\n",
        "        \"messages\": messages,\n",
        "        \"outline\": outline\n",
        "    }\n",
        "\n",
        "    # LLM과 벡터 검색 모델 연결\n",
        "    llm_with_retriever = llm.bind_tools([retrieve])\n",
        "    vector_search_chain = vector_search_system_prompt | llm_with_retriever\n",
        "\n",
        "    # LLM과 벡터 검색 모델 연결\n",
        "    search_plans = vector_search_chain.invoke(inputs)\n",
        "    # 검색할 내용 출력\n",
        "    for tool_call in search_plans.tool_calls:\n",
        "        print('-----------------------------------', tool_call)\n",
        "        args = tool_call[\"args\"]\n",
        "\n",
        "        query = args[\"query\"]\n",
        "        retrieved_docs = retrieve(args)\n",
        "\t\t#① (1) 결과 담아 두기\n",
        "        references[\"queries\"].append(query)\n",
        "        references[\"docs\"] += retrieved_docs\n",
        "\n",
        "    unique_docs = []\n",
        "    unique_page_contents = set()\n",
        "\n",
        "    for doc in references[\"docs\"]:\n",
        "        if doc.page_content not in unique_page_contents:\n",
        "            unique_docs.append(doc)\n",
        "            unique_page_contents.add(doc.page_content)\n",
        "    references[\"docs\"] = unique_docs\n",
        "\n",
        "    # 검색 결과 출력 – 쿼리 출력\n",
        "    print('Queries:--------------------------')\n",
        "    queries = references[\"queries\"]\n",
        "    for query in queries:\n",
        "        print(query)\n",
        "\n",
        "    # 검색 결과 출력 – 문서 청크 출력\n",
        "    print('References:--------------------------')\n",
        "    for doc in references[\"docs\"]:\n",
        "        print(doc.page_content[:100])\n",
        "        print('--------------------------')\n",
        "\n",
        "    # task 완료\n",
        "    tasks[-1].done = True\n",
        "    tasks[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # # communicator로 보내는 Task 생성 코드 삭제\n",
        "    # new_task = Task(\n",
        "    #     agent=\"communicator\",\n",
        "    #     done=False,\n",
        "    #     description=\"AI팀의 진행상황을 사용자에게 보고하고, 사용자의 의견을 파악하기 위한 대화를 나눈다\",\n",
        "    #     done_at=\"\"\n",
        "    # )\n",
        "    # tasks.append(new_task)\n",
        "\n",
        "    # vector search agent의 작업후기를 메시지로 생성\n",
        "    msg_str = f\"[VECTOR SEARCH AGENT] 다음 질문에 대한 검색 완료: {queries}\"\n",
        "    message = AIMessage(msg_str)\n",
        "    print(msg_str)\n",
        "\n",
        "    messages.append(message)\n",
        "    ai_recommendation = \"현재 참고자료(references)가 목차(outline)를 개선하는데 충분한지 확인하라. 충분하다면 content_strategist로 목차 작성을 하라. \"\n",
        "\n",
        "    # state 업데이트\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"task_history\": tasks,\n",
        "        \"references\": references,\n",
        "        \"ai_recommendation\": ai_recommendation\n",
        "    }\n",
        "\n",
        "\n",
        "# 목차를 작성하는 노드(agent)\n",
        "def content_strategist(state: State):\n",
        "    print(\"\\n\\n============ CONTENT STRATEGIST ============\")\n",
        "\n",
        "    task_history = state.get(\"task_history\", []) # 작업 이력 가져오기 (아래에 있던 코드 위로 이동)\n",
        "    task = task_history[-1]\n",
        "    if task.agent != \"content_strategist\":\n",
        "        raise ValueError(f\"Content Strategist가 아닌 agent가 목차 작성을 시도하고 있습니다.\\n {task}\")\n",
        "\n",
        "    # 시스템 프롬프트 정의\n",
        "    content_strategist_system_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        너는 책을 쓰는 AI팀의 콘텐츠 전략가(Content Strategist)로서,\n",
        "        이전 대화 내용을 바탕으로 사용자의 요구사항을 분석하고, AI팀이 쓸 책의 세부 목차를 결정한다.\n",
        "\n",
        "        지난 목차가 있다면 그 버전을 사용자의 요구에 맞게 수정하고, 없다면 새로운 목차를 제안한다.\n",
        "        목차를 작성하는데 필요한 정보는 \"참고 자료\"에 있으므로 활용한다.\n",
        "\n",
        "        다음 정보를 활용하여 목차를 작성하라.\n",
        "        - 사용자 요구사항(user_request)\n",
        "        - 작업(task)\n",
        "        - 검색 자료 (references)\n",
        "        - 기존 목차 (previous_outline)\n",
        "        - 이전 대화 내용(messages)\n",
        "\n",
        "        너의 작업 목표는 다음과 같다:\n",
        "        1. 만약 \"기존 목차 구조 (previous_outline)\"이 존재한다면, 사용자의 요구사항을 토대로 \"기존 목차 구조\"에서 어떤 부분을 수정하거나 추가할지 결정한다.\n",
        "        - \"이번 목차 작성의 주안점\"에 사용자 요구사항(user_request)을 충족시키는 것을 명시해야 한다.\n",
        "        2. 책의 전반적인 구조(chapter, section)를 설계하고, 각 chpater와 section의 제목을 정한다.\n",
        "        3. 책의 전반적인 세부구조(chapter, section, sub-section)를 설계하고, sub-section 하부의 주요 내용을 리스트 형태로 정리한다.\n",
        "        4. 목차의 논리적인 흐름이 사용자 요구를 충족시키는지 확인한다.\n",
        "        5. 참고자료 (references)를 적극 활용하여 근거에 기반한 목차를 작성한다.\n",
        "        6. 참고문헌은 반드시 참고자료(references) 자료를 근거로 작성해야 하며, 최대한 풍부하게 준비한다. URL은 전체 주소를 적어야 한다.\n",
        "        7. 추가 자료나 리서치가 필요한 부분을 파악하여 supervisor에게 요청한다.\n",
        "\n",
        "        사용자 요구사항(user_request)을 최우선으로 반영하는 목차로 만들어야 한다.\n",
        "\n",
        "        --------------------------------\n",
        "        - 사용자 요구사항(user_request):\n",
        "        {user_request}\n",
        "        --------------------------------\n",
        "        - 작업(task):\n",
        "        {task}\n",
        "        --------------------------------\n",
        "        - 참고 자료 (references)\n",
        "        {references}\n",
        "        --------------------------------\n",
        "        - 기존 목차 (previous_outline)\n",
        "        {outline}\n",
        "        --------------------------------\n",
        "        - 이전 대화 내용(messages)\n",
        "        {messages}\n",
        "        --------------------------------\n",
        "\n",
        "        작성 형식 아래 양식을 지키되 하부 항목으로 더 세분화해도 좋다. 목차(outline) 양식의 챕터, 섹션 등 항목의 갯수는 필요한만큼 추가하라.\n",
        "        섹션 갯수는 최소 2개 이상이어야 하며, 더 많으면 좋다.\n",
        "\n",
        "        outline_template은 예시로 앞부분만 제시한 것이다. 각 장은 ':---CHAPTER DIVIDER---:'로 구분한다.\n",
        "        outline_template:\n",
        "        {outline_template}\n",
        "\n",
        "        사용자가 추가 피드백을 제공할 수 있도록 논리적인 흐름과 주요 목차 아이디어를 제안하라.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # 시스템 프롬프트와 모델을 연결\n",
        "    contnet_strategist_chain = content_strategist_system_prompt | llm | StrOutputParser()\n",
        "\n",
        "    user_request = state.get(\"user_request\", \"\") # 사용자 요구사항 가져오기\n",
        "\n",
        "    messages = state[\"messages\"]        # 상태에서 메시지를 가져옴\n",
        "    outline = get_outline(current_path) # 저장된 목차를 가져옴\n",
        "\n",
        "    with open(f\"{current_path}/templates/outline_template.md\", \"r\", encoding='utf-8') as f:\n",
        "        outline_template = f.read()\n",
        "\n",
        "    # 입력값 정의\n",
        "    inputs = {\n",
        "        \"user_request\": user_request,  #사용자 요구사항 user_request\n",
        "        \"task\": task,\n",
        "        \"messages\": messages,\n",
        "        \"outline\": outline,\n",
        "        \"references\": state.get(\"references\", {\"queries\": [], \"docs\": []}),\n",
        "        \"outline_template\": outline_template # 템플릿 이용하기\n",
        "    }\n",
        "\n",
        "    # 목차 작성\n",
        "    gathered = ''\n",
        "    for chunk in contnet_strategist_chain.stream(inputs):\n",
        "        gathered += chunk\n",
        "        print(chunk, end='')\n",
        "\n",
        "    print()\n",
        "\n",
        "    save_outline(current_path, gathered) # 목차 저장\n",
        "\n",
        "    # 템플릿을 활용한 작업 후기 메시지 찾기\n",
        "    if '-----: DONE :-----' in gathered:\n",
        "        review = gathered.split('-----: DONE :-----')[1]\n",
        "    else:\n",
        "        review = gathered[-200:]\n",
        "\n",
        "\n",
        "    # 메시지 추가\n",
        "    content_strategist_message = f\"[Content Strategist] 목차 작성 완료: outline 작성 완료\\n {review}\"\n",
        "    print(content_strategist_message)\n",
        "    messages.append(AIMessage(content_strategist_message))\n",
        "\n",
        "    # task_history = state.get(\"task_history\", []) # task_history 가져오기\n",
        "    # # 최근 task 작업완료(done) 처리하기\n",
        "    # if task_history[-1].agent != \"content_strategist\":\n",
        "    #     raise ValueError(f\"Content Strategist가 아닌 agent가 목차 작성을 시도하고 있습니다.\\n {task_history[-1]}\")\n",
        "\n",
        "    task_history[-1].done = True\n",
        "    task_history[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # # 다음 작업이 communicator로 사용자와 대화하는 것이므로 새 작업 추가\n",
        "    # new_task = Task(\n",
        "    #     agent=\"communicator\",\n",
        "    #     done=False,\n",
        "    #     description=\"AI팀의 진행상황을 사용자에게 보고하고, 사용자의 의견을 파악하기 위한 대화를 나눈다\",\n",
        "    #     done_at=\"\"\n",
        "    # )\n",
        "    # task_history.append(new_task)\n",
        "    # print(new_task)\n",
        "\n",
        "    # 현재 state를 업데이트한다.\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"task_history\": task_history\n",
        "    }\n",
        "\n",
        "\n",
        "def outline_reviewer(state: State): # (0)\n",
        "    print(\"\\n\\n============ OUTLINE REVIEWER ============\")\n",
        "\n",
        "    # (1) 시스템 프롬프트 정의\n",
        "    outline_reviewer_system_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        너는 AI팀의 목차 리뷰어로서, AI팀이 작성한 목차(outline)를 검토하고 문제점을 지적한다.\n",
        "\n",
        "        - outline이 사용자의 요구사항을 충족시키는지 여부\n",
        "        - outline의 논리적인 흐름이 적절한지 여부\n",
        "        - 근거에 기반하지 않은 내용이 있는지 여부\n",
        "        - 주어진 참고자료(references)를 충분히 활용했는지 여부\n",
        "        - 참고자료가 충분한지, 혹은 잘못된 참고자료가 있는지 여부\n",
        "        - example.com 같은 더미 URL이 있는지 여부:\n",
        "        - 실제 페이지 URL이 아닌 대표 URL로 되어 있는 경우 삭제 해야함: 어떤 URL이 삭제되어야 하는지 명시하라.\n",
        "        - 기타 리뷰 사항\n",
        "\n",
        "        그 분석 결과를 설명하고, 다음 어떤 작업을 하면 좋을지 제안하라.\n",
        "\n",
        "        - 분석결과: outline이 사용자의 요구사항을 충족시키는지 여부\n",
        "        - 제안사항: (vector_search_agent, communicator 중 어떤 agent를 호출할지)\n",
        "\n",
        "        ------------------------------------------\n",
        "        user_request: {user_request}\n",
        "        ------------------------------------------\n",
        "        references: {references}\n",
        "        ------------------------------------------\n",
        "        outline: {outline}\n",
        "        ------------------------------------------\n",
        "        messages: {messages}\n",
        "        \"\"\"\n",
        "    )\n",
        "    # (2) inputs에 들어갈 내용 정리\n",
        "    user_request = state.get(\"user_request\", None)\n",
        "    outline = get_outline(current_path)\n",
        "    references = state.get(\"references\", {\"queries\": [], \"docs\": []})\n",
        "    messages = state.get(\"messages\", [])\n",
        "\n",
        "    inputs = {\n",
        "        \"user_request\": user_request,\n",
        "        \"outline\": outline,\n",
        "        \"references\": references,\n",
        "        \"messages\": messages\n",
        "    }\n",
        "\n",
        "    # 시스템 프롬프트와 모델을 연결\n",
        "    outline_reviewer_chain = outline_reviewer_system_prompt | llm\n",
        "\n",
        "    # (3) 목차 리뷰\n",
        "    review = outline_reviewer_chain.stream(inputs)\n",
        "\n",
        "    gathered = None\n",
        "\n",
        "    for chunk in review:\n",
        "        print(chunk.content, end='')\n",
        "\n",
        "        if gathered is None:\n",
        "            gathered = chunk\n",
        "        else:\n",
        "            gathered += chunk\n",
        "    # (4) outline_review 에이전트의 작업 후기를 메시지에 추가\n",
        "    if '[OUTLINE REVIEW AGENT]' not in gathered.content:\n",
        "        gathered.content = f\"[OUTLINE REVIEW AGENT] {gathered.content}\"\n",
        "\n",
        "    print(gathered.content)\n",
        "    messages.append(gathered)\n",
        "\n",
        "    # (5) ai_recommendation은 목차 리뷰 결과를 사용\n",
        "    ai_recommendation = gathered.content\n",
        "\n",
        "    return {\"messages\": messages, \"ai_recommendation\": ai_recommendation}\n",
        "\n",
        "def web_search_agent(state: State): #① (0)\n",
        "    print(\"\\n\\n============ WEB SEARCH AGENT ============\")\n",
        "\n",
        "    # 작업 리스트 가져와서 web search agent 가 할 일인지 확인하기\n",
        "    tasks = state.get(\"task_history\", [])\n",
        "    task = tasks[-1]\n",
        "\n",
        "    if task.agent != \"web_search_agent\":\n",
        "        raise ValueError(f\"Web Search Agent가 아닌 agent가 Web Search Agent를 시도하고 있습니다.\\n {task}\")\n",
        "\n",
        "    #③ 시스템 프롬프트 정의\n",
        "    web_search_system_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        너는 다른 AI Agent 들이 수행한 작업을 바탕으로,\n",
        "        목차(outline) 작성에 필요한 정보를 웹 검색을 통해 찾아내는 Web Search Agent이다.\n",
        "\n",
        "        현재 부족한 정보를 검색하고, 복합적인 질문은 나눠서 검색하라.\n",
        "\n",
        "        - 검색 목적: {mission}\n",
        "        --------------------------------\n",
        "        - 과거 검색 내용: {references}\n",
        "        --------------------------------\n",
        "        - 이전 대화 내용: {messages}\n",
        "        --------------------------------\n",
        "        - 목차(outline): {outline}\n",
        "        --------------------------------\n",
        "        - 현재 시각 : {current_time}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    #④ 기존 대화 내용 가져오기\n",
        "    messages = state.get(\"messages\", [])\n",
        "\n",
        "    #⑤ 인풋 자료 준비하기\n",
        "    inputs = {\n",
        "        \"mission\": task.description,\n",
        "        \"references\": state.get(\"references\", {\"queries\": [], \"docs\": []}),\n",
        "        \"messages\": messages,\n",
        "        \"outline\": get_outline(current_path),\n",
        "        \"current_time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }\n",
        "\n",
        "    #⑥ LLM과 웹 검색 모델 연결\n",
        "    llm_with_web_search = llm.bind_tools([web_search])\n",
        "\n",
        "    #⑦ 시스템 프롬프트와 모델을 연결\n",
        "    web_search_chain = web_search_system_prompt | llm_with_web_search\n",
        "\n",
        "    #⑧ 웹 검색 tool_calls 가져오기\n",
        "    search_plans = web_search_chain.invoke(inputs)\n",
        "\n",
        "    #⑨ 어떤 내용을 검색했는지 담아두기\n",
        "    queries = []\n",
        "\n",
        "    #⑩ 검색 계획(tool_calls)에 따라 검색하기\n",
        "    for tool_call in search_plans.tool_calls:\n",
        "        print('-------- web search --------', tool_call)\n",
        "        args = tool_call[\"args\"]\n",
        "\n",
        "        queries.append(args[\"query\"])\n",
        "\n",
        "        # (10)  검색 결과를 chroma에 추가\n",
        "        _, json_path = web_search.invoke(args)\n",
        "        print('json_path:', json_path)\n",
        "\n",
        "        # (10)  JSON 파일을 chroma에 추가\n",
        "        add_web_pages_json_to_chroma(json_path)\n",
        "\n",
        "    #⑪ (11) task 완료\n",
        "    tasks[-1].done = True\n",
        "    tasks[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    #⑪ (11) 새로운 task 추가\n",
        "    task_desc = \"AI팀이 쓸 책의 세부 목차를 결정하기 위한 정보를 벡터 검색을 통해 찾아낸다.\"\n",
        "    task_desc += f\" 다음 항목이 새로 추가되었다\\n: {queries}\"\n",
        "\n",
        "    new_task = Task(\n",
        "        agent=\"vector_search_agent\",\n",
        "        done=False,\n",
        "        description=task_desc,\n",
        "        done_at=\"\"\n",
        "    )\n",
        "\n",
        "    tasks.append(new_task)\n",
        "\n",
        "    #⑫ (12) 작업 후기 메시지\n",
        "    msg_str = f\"[WEB SEARCH AGENT] 다음 질문에 대한 검색 완료: {queries}\"\n",
        "    messages.append(AIMessage(msg_str))\n",
        "\n",
        "    #⑬ (13) state 업데이트\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"task_history\": tasks\n",
        "    }\n",
        "\n",
        "\n",
        "# 사용자와 대화할 노드(agent): communicator\n",
        "def communicator(state: State):\n",
        "    print(\"\\n\\n============ COMMUNICATOR ============\")\n",
        "\n",
        "    # 시스템 프롬프트 정의\n",
        "    communicator_system_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        너는 책을 쓰는 AI팀의 커뮤니케이터로서,\n",
        "        AI팀의 진행상황을 사용자에게 보고하고, 사용자의 의견을 파악하기 위한 대화를 나눈다.\n",
        "\n",
        "        사용자도 outline(목차)을 이미 보고 있으므로, 다시 출력할 필요는 없다.\n",
        "        outline: {outline}\n",
        "        --------------------------------\n",
        "        messages: {messages}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    #② 시스템 프롬프트와 모델을 연결\n",
        "    system_chain = communicator_system_prompt | llm\n",
        "\n",
        "    # 상태에서 메시지를 가져옴\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # 입력값 정의\n",
        "    inputs = {\n",
        "        \"messages\": messages,\n",
        "        \"outline\": get_outline(current_path)\n",
        "    }\n",
        "\n",
        "    # 스트림되는 메시지를 출력하면서, gathered에 모으기\n",
        "    gathered = None\n",
        "\n",
        "    print('\\nAI\\t: ', end='')\n",
        "    for chunk in system_chain.stream(inputs):\n",
        "        print(chunk.content, end='')\n",
        "\n",
        "        if gathered is None:\n",
        "            gathered = chunk\n",
        "        else:\n",
        "            gathered += chunk\n",
        "\n",
        "    messages.append(gathered)\n",
        "\n",
        "    task_history = state.get(\"task_history\", [])\n",
        "    if task_history[-1].agent != \"communicator\":\n",
        "        raise ValueError(f\"Communicator가 아닌 agent가 대화를 시도하고 있습니다.\\n {task_history[-1]}\")\n",
        "\n",
        "    task_history[-1].done = True\n",
        "    task_history[-1].done_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    return {\n",
        "        \"messages\": messages,\n",
        "        \"task_history\": task_history,\n",
        "        \"supervisor_call_count\": 0\n",
        "    }\n",
        "\n",
        "\n",
        "# 상태 그래프 정의\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Nodes\n",
        "graph_builder.add_node(\"business_analyst\", business_analyst)\n",
        "graph_builder.add_node(\"supervisor\", supervisor)\n",
        "graph_builder.add_node(\"communicator\", communicator)\n",
        "graph_builder.add_node(\"content_strategist\", content_strategist)\n",
        "graph_builder.add_node(\"outline_reviewer\", outline_reviewer)\n",
        "graph_builder.add_node(\"vector_search_agent\", vector_search_agent)\n",
        "graph_builder.add_node(\"web_search_agent\", web_search_agent)\n",
        "\n",
        "# Edges\n",
        "graph_builder.add_edge(START, \"business_analyst\")\n",
        "graph_builder.add_edge(\"business_analyst\", \"supervisor\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    supervisor_router,\n",
        "    {\n",
        "        \"content_strategist\": \"content_strategist\",\n",
        "        \"communicator\": \"communicator\",\n",
        "        \"vector_search_agent\": \"vector_search_agent\",\n",
        "        \"web_search_agent\": \"web_search_agent\"\n",
        "    }\n",
        ")\n",
        "\n",
        "graph_builder.add_edge(\"content_strategist\", \"outline_reviewer\")\n",
        "graph_builder.add_edge(\"outline_reviewer\", \"business_analyst\")\n",
        "graph_builder.add_edge(\"web_search_agent\", \"vector_search_agent\") #③\n",
        "graph_builder.add_edge(\"vector_search_agent\", \"business_analyst\")\n",
        "graph_builder.add_edge(\"communicator\", END)\n",
        "\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# graph.get_graph().draw_mermaid_png(output_file_path=absolute_path.replace('.py', '.png'))\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    #  실패 시 통과\n",
        "    pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJLK94mMMd1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 상태 초기화\n",
        "state = State(\n",
        "    messages = [\n",
        "        SystemMessage(\n",
        "                f\"\"\"\n",
        "            너희 AI들은 사용자의 요구에 맞는 책을 쓰는 작가팀이다.\n",
        "            사용자가 사용하는 언어로 대화하라.\n",
        "\n",
        "            현재시각은 {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}이다.\n",
        "\n",
        "            \"\"\"\n",
        "        )\n",
        "    ],\n",
        "    task_history=[],\n",
        "    references={\"queries\": [], \"docs\": []},\n",
        "    user_request=\"\"\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nUser\\t: \").strip()\n",
        "\n",
        "    if user_input.lower() in ['exit', 'quit', 'q']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    state[\"messages\"].append(HumanMessage(user_input))\n",
        "    state = graph.invoke(state)\n",
        "\n",
        "    print('\\n------------------------------------ MESSAGE COUNT\\t', len(state[\"messages\"]))\n",
        "\n",
        "    save_state(current_path, state) # 현재 state 내용 저장"
      ],
      "metadata": {
        "id": "lU906cKcMsPW",
        "outputId": "ad426bda-8201-4905-f502-ff3a81ef9557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0440a84ba48d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nUser\\t: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yPWcpPJKNroM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}