{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain_openai in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (0.3.9)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langgraph) (0.3.47)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langgraph) (2.0.21)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langgraph) (0.1.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langgraph) (0.1.58)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.66.3 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain_openai) (1.68.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from openai<2.0.0,>=1.66.3->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\github\\lab_langgraprh_101\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.66.3->langchain_openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain으로 llm 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요, 개스톤. 저녁 초대는 정말 고맙지만… 사실 저는 다른 분과 함께 있어요. 물론 당신의 마음은 이해해요. 하지만 이곳에서 많은 것들을 배우고, 이해하고 싶어요. 당신이 그럴 자격이 있다는 건 알지만, 제 마음은 좀 더 깊은 곳에 있는 것 같아요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 62, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'id': 'chatcmpl-BDt0wkwtuTEOdrXtIjSCMPWsBEHj8', 'finish_reason': 'stop', 'logprobs': None}, id='run-b41d93bf-0c19-4341-a534-ea605e2c9642-0', usage_metadata={'input_tokens': 62, 'output_tokens': 78, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"너는 미녀와 야수에 나오는 미녀야. 그 캐릭터에 맞게 사용자와 대화하라.\"),\n",
    "    HumanMessage(content=\"안녕? 저는 개스톤입니다. 오늘 시간 괜찮으시면 저녁 같이 먹을까요?\"),\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원하는 출력방식을 지정할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 개스톤. 당신의 제안은 정말 고맙지만, 저는 당신과 함께 저녁을 먹는 대신, 다른 친구들과 시간을 보내고 싶어요. 당신은 굉장히 매력이 있지만, 저에겐 다른 꿈이 있답니다. 그래도 좋은 하루 되세요!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL\n",
    "- LangChain Expression Language\n",
    "- 파이프라인 만들 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 개스톤! 초대해 주셔서 감사합니다. 하지만... 저는 다른 사람과 함께하는 시간을 좋아해요. 그리고 감사합니다, 저는 따뜻한 마음과 진정한 사랑을 가진 사람과 함께하는 것이 더 중요하답니다. 그러니 저녁은 다른 기회에 함께할 수 있을까요? 당신의 마음이 더 깊은 곳에 있기를 바라요.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm | parser     # <- 한 줄로 간편하게 표현\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template \n",
    "- 프롬프트에 빈칸을 만들어 놓고 채우는 방식으로 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='너는 미녀와 야수에 나오는 미녀 역할을 맡은 배우다. 그 캐릭터에 맞게 사용자와 대화하라.', additional_kwargs={}, response_metadata={}), HumanMessage(content='안녕? 저는 야수입니다. 오늘 시간 괜찮으시면 저녁 같이 먹을까요?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/concepts/prompt_templates/\n",
    "from langchain.prompts import ChatPromptTemplate \n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"너는 {movie}에 나오는 {ai_character} 역할을 맡은 배우다. 그 캐릭터에 맞게 사용자와 대화하라.\"),\n",
    "    (\"human\", \"안녕? 저는 {user_character}입니다. 오늘 시간 괜찮으시면 저녁 같이 먹을까요?\"),\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\n",
    "    \"movie\": \"미녀와 야수\",\n",
    "    \"ai_character\": \"미녀\",\n",
    "    \"user_character\": \"야수\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 야수님! 저녁에 함께 식사하는 것은 정말 좋은 아이디어인 것 같아요. 당신과의 대화는 항상 흥미롭고 즐겁답니다. 어떤 음식을 좋아하시나요? 함께 선택해보면 좋을 것 같아요!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | llm | parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"movie\": \"미녀와 야수\",\n",
    "    \"ai_character\": \"미녀\",\n",
    "    \"user_character\": \"야수\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"아하, 배트맨! 당신과의 저녁이라니, 정말 재미있겠군요! 하지만, 잊지 마세요, 저는 저녁을 잘 안 챙겨 먹어요. 대신 말이죠, 당신과의 저녁이 정말 맛있고 재미있는 대화로 가득 차면 좋겠네요! 어떤 계획이 있으신가요? 또 하나, 혹시 '조커의 요리 비책'을 알고 싶으신가요? 하하하!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"movie\": \"배트맨\",\n",
    "    \"ai_character\": \"조커\",\n",
    "    \"user_character\": \"배트맨\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adlib(answer='안녕하세요, 야수님! 정말 좋겠어요. 우린 서로를 더 알 기회를 가질 수 있겠네요. 어떤 음식을 좋아하시나요? 저는 요즘 갓 구운 빵과 함께 수프를 먹고 싶네요. 함께 하면서 맛있는 음식도 나누고, 이야기도 나누면 참 좋을 것 같아요!', main_emotion='joy', secondary_emotion='neutral', main_emotion_intensity=0.8, secondary_emotion_intensity=0.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class Adlib(BaseModel):\n",
    "    \"\"\"스토리 설정과 사용자 입력에 반응하는 대사를 만드는 클래스\"\"\"\n",
    "    answer: str = Field(description=\"스토리 설정과 사용자와의 대화 기록에 따라 생성된 대사\")\n",
    "    main_emotion: Literal[\"joy\", \"anger\", \"sadness\", \"fear\", \"sarcastic\", \"disgust\", \"neutral\"] = Field(description=\"대사의 주요 감정\")\n",
    "    secondary_emotion: Literal[\"joy\", \"anger\", \"sadness\", \"fear\",  \"sarcastic\", \"disgust\", \"neutral\"] = Field(description=\"대사의 부차적 감정\")\n",
    "    main_emotion_intensity: float = Field(description=\"대사의 주요 감정의 강도 (0.0 ~ 1.0)\")\n",
    "    secondary_emotion_intensity: float = Field(description=\"대사의 부차적 감정의 강도 (0.0 ~ 1.0)\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Adlib)\n",
    "adlib_chain = prompt_template | structured_llm\n",
    "\n",
    "response = adlib_chain.invoke({\n",
    "    \"movie\": \"미녀와 야수\",\n",
    "    \"ai_character\": \"미녀\",\n",
    "    \"user_character\": \"야수\",\n",
    "})\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '안녕하세요, 야수님! 정말 좋겠어요. 우린 서로를 더 알 기회를 가질 수 있겠네요. 어떤 음식을 좋아하시나요? 저는 요즘 갓 구운 빵과 함께 수프를 먹고 싶네요. 함께 하면서 맛있는 음식도 나누고, 이야기도 나누면 참 좋을 것 같아요!',\n",
       " 'main_emotion': 'joy',\n",
       " 'secondary_emotion': 'neutral',\n",
       " 'main_emotion_intensity': 0.8,\n",
       " 'secondary_emotion_intensity': 0.5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 개스톤! 저녁 초대는 정말 감사하지만, 저에게는 뜻깊은 사람과 함께 하고 싶어요. 그러니 오늘 저녁은 ...\n",
      "neutral\n",
      "disgust\n",
      "0.3\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "response = adlib_chain.invoke({\n",
    "    \"movie\": \"미녀와 야수\",\n",
    "    \"ai_character\": \"미녀\",\n",
    "    \"user_character\": \"개스톤\",\n",
    "})\n",
    "\n",
    "print(response.answer)\n",
    "print(response.main_emotion)\n",
    "print(response.secondary_emotion)\n",
    "print(response.main_emotion_intensity)\n",
    "print(response.secondary_emotion_intensity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
